{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Grab data from ACS with cenpy (don't need to run every time!)\n",
    "# Variables:\n",
    "#    - total population (B01003_001E)\n",
    "#    - total white (B02008_001E)\n",
    "#    - total black (B02009_001E)\n",
    "#    - total asian (B02011_001E)\n",
    "#    - total hispanic (B03001_003E)\n",
    "#    - median household income (B19013_001E)\n",
    "#    - median house price (B25077_001E)\n",
    "#    - total tenure (B25032_001E)\n",
    "#    - total owner occupied (B25032_002E)\n",
    "#    - total renter occupied (B25032_007E)\n",
    "#    - median contract rent (B25064_001E)\n",
    "#    - total in labor force (B23025_002E)\n",
    "#    - total employed (civilian) (B23025_004E)\n",
    "#    - total unemployed (civilian) (B23025_005E)\n",
    "\n",
    "countydata = gpd.GeoDataFrame()\n",
    "\n",
    "states = pd.read_csv('../utils/states.csv')['State'].values\n",
    "for state in tqdm(states):\n",
    "    countydata = countydata.append(acs.from_state(state=state, variables=variables, level='county'))\n",
    "\n",
    "countydata.to_csv('../data/ACS_countydata.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import stan_jupyter as stan\n",
    "from scipy.linalg import norm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from cenpy.products import ACS\n",
    "from spint.gravity import Gravity, Attraction, Production\n",
    "\n",
    "acs = ACS()\n",
    "LA_FIPS = '06037'  # LA County FIPS code\n",
    "variables = ['B01003_001E', 'B02008_001E', 'B02009_001E', 'B02011_001E', 'B03001_003E', \\\n",
    "    'B19013_001E', 'B25077_001E', 'B25032_001E', 'B25032_002E', 'B25032_007E', \\\n",
    "    'B25064_001E', 'B23025_002E', 'B23025_004E', 'B23025_005E']\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Flows\n",
    "inflows_raw = pd.read_csv('../data/LACounty_ACS_2014_2018_All_IN.csv', usecols=['State/County FIPS', 'Total', 'Margin of Error (+/-)']).replace(\"'\", \"\", regex=True)\n",
    "outflows_raw = pd.read_csv('../data/LACounty_ACS_2014_2018_All_OUT.csv', usecols=['State/County FIPS', 'Total', 'Margin of Error (+/-)']).replace(\"'\", \"\", regex=True)\n",
    "outflows_raw.rename(columns={'State/County FIPS' : 'destFIPS', 'Total' : 'total_out', 'Margin of Error (+/-)' : 'outMOE'}, inplace=True)\n",
    "inflows_raw.rename(columns={'State/County FIPS' : 'originFIPS', 'Total' : 'total_in', 'Margin of Error (+/-)' : 'inMOE'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# County-level demographic data (and convert covariate columns)\n",
    "countydata = gpd.read_file('../data/ACS_countydata.csv', GEOM_POSSIBLE_NAMES=\"geometry\", KEEP_GEOM_COLUMNS=\"NO\").replace('', 0)\n",
    "for var in variables:\n",
    "    countydata[var] = countydata[var].astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Ping ACS for data for LA county\n",
    "la_data = acs.from_county(\"Los Angeles County, CA\", variables=variables, level='county')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Convert races, employment to percents\n",
    "countydata['pctwhite'] = countydata['B02008_001E'] / countydata['B01003_001E']\n",
    "countydata['pctblack'] = countydata['B02009_001E'] / countydata['B01003_001E']\n",
    "countydata['pctasian'] = countydata['B02011_001E'] / countydata['B01003_001E']\n",
    "countydata['pcthispa'] = countydata['B03001_003E'] / countydata['B01003_001E']\n",
    "countydata['pctemplo'] = countydata['B23025_004E'] / countydata['B23025_002E']\n",
    "countydata['pctunemp'] = countydata['B23025_005E'] / countydata['B23025_002E']\n",
    "countydata['pctowner'] = countydata['B25032_002E'] / countydata['B25032_001E']\n",
    "countydata['pctrentr'] = countydata['B25032_007E'] / countydata['B25032_001E']\n",
    "\n",
    "la_data['pctwhite'] = la_data['B02008_001E'] / la_data['B01003_001E']\n",
    "la_data['pctblack'] = la_data['B02009_001E'] / la_data['B01003_001E']\n",
    "la_data['pctasian'] = la_data['B02011_001E'] / la_data['B01003_001E']\n",
    "la_data['pcthispa'] = la_data['B03001_003E'] / la_data['B01003_001E']\n",
    "la_data['pctemplo'] = la_data['B23025_004E'] / la_data['B23025_002E']\n",
    "la_data['pctunemp'] = la_data['B23025_005E'] / la_data['B23025_002E']\n",
    "la_data['pctowner'] = la_data['B25032_002E'] / la_data['B25032_001E']\n",
    "la_data['pctrentr'] = la_data['B25032_007E'] / la_data['B25032_001E']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Rename remaining columns and record plaintext variables\n",
    "countydata.rename(columns={'B25064_001E' : 'medrent', 'B19013_001E' : 'medincome', 'B25077_001E' : 'medhprice'}, inplace=True)\n",
    "plainvars = ['pctblack']\n",
    "# plainvars = ['pctwhite', 'pctblack', 'pctasian', 'pcthispa', \\\n",
    "#     'medincome', 'medhprice', 'pctowner', 'pctrentr', \\\n",
    "#     'medrent', 'pctemplo', 'pctunemp']\n",
    "# Problems: medincome, medhprice, medrent: one or more arrays have missing or NaN\n",
    "#           pctowner, pctrentr, pctemplo, pctunemp: gives NaN SE and tvalues in origin field"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rearrage data to prep for analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Merge all the data into one big dataframe to make it simpler\n",
    "data = pd.merge(pd.merge(countydata, outflows_raw, how='inner', left_on='GEOID', right_on='destFIPS'), inflows_raw, how='inner', left_on='GEOID', right_on='originFIPS').set_crs(epsg=3395)\n",
    "la_data.rename(columns={'B25064_001E' : 'medrent', 'B19013_001E' : 'medincome', 'B25077_001E' : 'medhprice'}, inplace=True)\n",
    "la_covars = np.tile(la_data[plainvars].values, (data.shape[0], 1))  # repeat the data so that we account for the single location properly"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# costs are all distances between LA and the out or in destination\n",
    "coords = np.hstack((data.centroid.x.values.reshape(-1, 1), data.centroid.y.values.reshape(-1, 1)))\n",
    "la_coords = np.array([la_data.centroid.x[0], la_data.centroid.y[0]])\n",
    "cost = norm(la_coords - coords, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Standardize all columns\n",
    "std_la = (np.exp(la_covars) - np.exp(la_covars).mean()) / np.exp(la_covars).std()\n",
    "std_data = (np.exp(data[plainvars].values) - np.mean(np.exp(data[plainvars].values))) / np.std(np.exp(data[plainvars].values))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calibrate model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model = Gravity(flows=data['total_out'].values.reshape(-1, 1), o_vars=np.exp(la_covars), d_vars=np.exp(data[plainvars].values), cost=cost, cost_func='exp', constant=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "paramnames = [*[x + '_o' for x in plainvars], *[x + '_d' for x in plainvars], 'distance']\n",
    "pd.DataFrame(data={'paramname' : paramnames, 'paramval' : model.params, 'SE' : model.std_err, 'tvalue' : model.tvalues, 'pvalue' : model.pvalues})  # origin attrs, dest attrs, distance"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paramname</th>\n",
       "      <th>paramval</th>\n",
       "      <th>SE</th>\n",
       "      <th>tvalue</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pctblack_o</td>\n",
       "      <td>90.211943</td>\n",
       "      <td>2.253481e-02</td>\n",
       "      <td>4003.226360</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pctblack_d</td>\n",
       "      <td>4.520015</td>\n",
       "      <td>9.555046e-03</td>\n",
       "      <td>473.050045</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distance</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>1.243465e-09</td>\n",
       "      <td>-1077.835486</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paramname   paramval            SE       tvalue  pvalue\n",
       "0  pctblack_o  90.211943  2.253481e-02  4003.226360     0.0\n",
       "1  pctblack_d   4.520015  9.555046e-03   473.050045     0.0\n",
       "2    distance  -0.000001  1.243465e-09 -1077.835486     0.0"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model.SSI  # wow this is...truly terrible"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.31970697864023123"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bayesian code -- RUNS OUT OF MEMORY\n",
    "(just for kicks)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gravity_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> n;      // number of flows\n",
    "    int<lower=1> k_d;    // number of variables at destinations\n",
    "    int<lower=1> k_o;    // number of variables at origins\n",
    "    int f[n];            // flows\n",
    "    matrix[n, k_d] X_d;  // data at destinations\n",
    "    matrix[n, k_o] X_o;  // data at origins\n",
    "    vector[n] dist;      // distances for each flow\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    vector[k_o] beta_o;       // origin parameters\n",
    "    vector[k_d] beta_d;       // destination parameters\n",
    "    real<upper=0> beta_dist;  // distance decay parameter\n",
    "    real alpha;               // intercept\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "    vector[n] mu = exp(alpha + log(X_o)*beta_o + log(X_d)*beta_d - beta_dist*log(dist));  // mean of flow process\n",
    "}\n",
    "\n",
    "model {\n",
    "    f ~ poisson(mu);\n",
    "\n",
    "    // priors -- uninformed for everything but beta_dist\n",
    "    beta_o ~ normal(0, 5);\n",
    "    beta_d ~ normal(0, 5);\n",
    "    beta_dist ~ normal(0, 1);\n",
    "    alpha ~ normal(0, 5);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "\n",
    "}\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# RUNS OUT OF MEMORY\n",
    "gravity_data = {\n",
    "    \"n\" : data['total_out'].shape[0],\n",
    "    \"f\" : data['total_out'].values,\n",
    "    \"k_d\" : np.exp(la_covars).shape[1],\n",
    "    \"k_o\" : np.exp(data[plainvars].values).shape[1],\n",
    "    \"X_d\" : np.exp(la_covars),\n",
    "    \"X_o\" : np.exp(data[plainvars].values),\n",
    "    \"dist\" : cost\n",
    "}\n",
    "\n",
    "gravity_posterior = stan.build(gravity_code, data=gravity_data)\n",
    "gravity_fit = gravity_posterior.sample(num_chains=3, num_warmup=9000, num_samples=1000, save_warmup=False)\n",
    "gravity_results = gravity_fit.to_frame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constrained models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "out_model = Production(flows=data['total_out'].values, origins=data['originFIPS'].values, d_vars=data[variables].values, cost=cost, cost_func='exp')\n",
    "in_model = Attraction(flows=data['total_in'].values, destinations=data['destFIPS'].values, o_vars=data[variables].values, cost=cost, cost_func='exp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('gds': conda)"
  },
  "interpreter": {
   "hash": "05bb042d27996769e72b34b93ada6e8056fd2ffd7f17b5cdf237e3c21ee9984a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}